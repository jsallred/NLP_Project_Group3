{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e24c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article, ArticleException\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1275d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get political bias dataset - for categorizing publishers\n",
    "REPO_ID = \"valurank/PoliticalBias\"\n",
    "\n",
    "df1 = pd.read_csv(\n",
    "    hf_hub_download(repo_id=REPO_ID, filename='Part1.csv', repo_type=\"dataset\")\n",
    ")\n",
    "df1 = pd.DataFrame(df1)\n",
    "df2 = pd.read_csv(\n",
    "    hf_hub_download(repo_id=REPO_ID, filename='Part2.csv', repo_type=\"dataset\")\n",
    ")\n",
    "df2 = pd.DataFrame(df2)\n",
    "df = df1._append(df2)\n",
    "df = df.drop(columns='Main URL')\n",
    "df.to_csv('politicalBias_urls.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6347e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Progress:   0%|          | 1/6253 [00:01<1:47:43,  1.03s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 2/6253 [00:01<1:29:37,  1.16it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 3/6253 [00:02<1:19:52,  1.30it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 4/6253 [00:04<2:28:29,  1.43s/it]WWWWWWW\n",
      "Scraping Progress:   0%|          | 5/6253 [00:05<1:58:56,  1.14s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 6/6253 [00:06<1:44:04,  1.00it/s]WWWWWWW\n",
      "Scraping Progress:   0%|          | 7/6253 [00:06<1:35:20,  1.09it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 8/6253 [00:07<1:23:11,  1.25it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 9/6253 [00:07<1:11:37,  1.45it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 10/6253 [00:09<1:27:06,  1.19it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 11/6253 [00:09<1:10:31,  1.48it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 12/6253 [00:10<1:13:38,  1.41it/s]WWWWWWW\n",
      "Scraping Progress:   0%|          | 13/6253 [00:10<1:00:24,  1.72it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 14/6253 [00:10<51:14,  2.03it/s]  WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 15/6253 [00:11<57:22,  1.81it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 16/6253 [00:11<54:51,  1.89it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 17/6253 [00:12<48:07,  2.16it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 18/6253 [00:12<45:20,  2.29it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 19/6253 [00:12<42:18,  2.46it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 20/6253 [00:13<57:59,  1.79it/s]WWWWWWW\n",
      "Scraping Progress:   0%|          | 21/6253 [00:14<51:25,  2.02it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 22/6253 [00:14<55:01,  1.89it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 23/6253 [00:15<1:10:49,  1.47it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 24/6253 [00:16<1:04:06,  1.62it/s]WWWWWWW\n",
      "Scraping Progress:   0%|          | 25/6253 [00:16<57:20,  1.81it/s]  WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 26/6253 [00:17<53:52,  1.93it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 27/6253 [00:17<55:37,  1.87it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 28/6253 [00:18<51:17,  2.02it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 29/6253 [00:18<55:58,  1.85it/s]WWWWWWW\n",
      "Scraping Progress:   0%|          | 30/6253 [00:20<1:24:27,  1.23it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   0%|          | 31/6253 [00:21<1:31:41,  1.13it/s]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 32/6253 [00:22<1:47:53,  1.04s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 34/6253 [00:31<4:10:21,  2.42s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 35/6253 [00:36<5:47:25,  3.35s/it]WWWWWWW\n",
      "Scraping Progress:   1%|          | 36/6253 [00:44<7:48:21,  4.52s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 37/6253 [00:47<7:00:45,  4.06s/it]WWWWWWW\n",
      "Scraping Progress:   1%|          | 38/6253 [00:48<5:25:08,  3.14s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 39/6253 [00:50<5:07:49,  2.97s/it]WWWWWWW\n",
      "Scraping Progress:   1%|          | 40/6253 [00:51<3:48:44,  2.21s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "Scraping Progress:   1%|          | 41/6253 [00:52<3:22:27,  1.96s/it]WWWWWWW\n",
      "WWWWWWW\n",
      "WWWWWWW\n"
     ]
    }
   ],
   "source": [
    "# scrape data to get (url,label,content)\n",
    "# send to file\n",
    "# will take hours\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('politicalBias_urls.csv')\n",
    "\n",
    "PoliticalBias_scraped = pd.DataFrame(columns=['url','label', 'text'])\n",
    "success, miss = 0, 0\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Scraping Progress\"):\n",
    "\n",
    "    # Iterate over items in the row\n",
    "    for column, value in row.items():\n",
    "        if value != np.nan:\n",
    "            try:\n",
    "                url = str(value)\n",
    "                article = Article(url)\n",
    "                article.download()\n",
    "                article.parse()\n",
    "                PoliticalBias_scraped = PoliticalBias_scraped._append({'url':url ,'label': column, 'text': article.text}, ignore_index=True)\n",
    "                success += 1\n",
    "            except ArticleException:\n",
    "                #print('***FAILED TO DOWNLOAD***', url)\n",
    "                miss += 1\n",
    "                pass\n",
    "\n",
    "rate = success/(miss + success)\n",
    "print(rate)\n",
    "PoliticalBias_scraped.to_csv('./scraped_data/politicalBias_scraped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b6c569",
   "metadata": {},
   "outputs": [
    {
     "ename": "EntryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-6614557f-4caebee276ec657433dc8a58;9c284105-7685-4e14-8e49-ff114554f8c3)\n\nEntry Not Found for url: https://huggingface.co/datasets/mediabiasgroup/BABE/resolve/main/BABE.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/mediabiasgroup/BABE/resolve/main/BABE.csv",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/bowmanrussell/Documents/Natural Language Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m REPO_ID \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmediabiasgroup/BABE\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     hf_hub_download(repo_id\u001b[39m=\u001b[39;49mREPO_ID, filename\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mBABE.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, repo_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df1 \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1260\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m         metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1262\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1263\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1264\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1265\u001b[0m             timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1266\u001b[0m             library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m   1267\u001b[0m             library_version\u001b[39m=\u001b[39;49mlibrary_version,\n\u001b[1;32m   1268\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1269\u001b[0m         )\n\u001b[1;32m   1270\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m         \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m         commit_hash \u001b[39m=\u001b[39m http_error\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1667\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1664\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39mAccept-Encoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[39m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1667\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1668\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1669\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1670\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1671\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1672\u001b[0m     follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1673\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1674\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1675\u001b[0m )\n\u001b[1;32m   1676\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1678\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m    386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    387\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    388\u001b[0m         follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    389\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    392\u001b[0m     \u001b[39m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[39m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m300\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m399\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:409\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 409\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    410\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:315\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEntryNotFound\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    314\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEntry Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m EntryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGatedRepo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    318\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot access gated repo for url \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6614557f-4caebee276ec657433dc8a58;9c284105-7685-4e14-8e49-ff114554f8c3)\n\nEntry Not Found for url: https://huggingface.co/datasets/mediabiasgroup/BABE/resolve/main/BABE.csv."
     ]
    }
   ],
   "source": [
    "# get BABE dataset - used to train and test models\n",
    "# BABE changed its file storage type to a zip for storage so this is feature no longer works. Content is stored in urls_BABE.csv\n",
    "REPO_ID = \"mediabiasgroup/BABE\"\n",
    "\n",
    "df1 = pd.read_csv(\n",
    "    hf_hub_download(repo_id=REPO_ID, filename='BABE.csv', repo_type=\"dataset\")\n",
    ")\n",
    "df1 = pd.DataFrame(df1)\n",
    "\n",
    "df1 = df1.dropna()\n",
    "\n",
    "df1.to_csv('urls_BABE.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relable_class(row):\n",
    "    if row['type_class'] == 'left':\n",
    "        return 0\n",
    "    elif row['type_class'] == 'center':\n",
    "        return 1\n",
    "    elif row['type_class'] == 'right':\n",
    "        return 2\n",
    "    else:\n",
    "        return row['type_class']  # Return the original value if not one of the specified types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6735bcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644\n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "1  https://www.alternet.org/2020/06/law-and-order...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "1  Mark Twain's instruction to curious residents ...       left  \n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "1  https://www.alternet.org/2020/06/law-and-order...   \n",
      "2  https://www.nbcnews.com/news/latino/after-step...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "1  Mark Twain's instruction to curious residents ...       left  \n",
      "2  It wasn't the content of White House adviser S...       left  \n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "1  https://www.alternet.org/2020/06/law-and-order...   \n",
      "2  https://www.nbcnews.com/news/latino/after-step...   \n",
      "3  https://www.alternet.org/2019/07/fox-news-has-...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "1  Mark Twain's instruction to curious residents ...       left  \n",
      "2  It wasn't the content of White House adviser S...       left  \n",
      "3  Donald Trump thinks white nationalism is going...       left  \n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "1  https://www.alternet.org/2020/06/law-and-order...   \n",
      "2  https://www.nbcnews.com/news/latino/after-step...   \n",
      "3  https://www.alternet.org/2019/07/fox-news-has-...   \n",
      "4  https://www.alternet.org/2019/08/a-new-low-was...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "1  Mark Twain's instruction to curious residents ...       left  \n",
      "2  It wasn't the content of White House adviser S...       left  \n",
      "3  Donald Trump thinks white nationalism is going...       left  \n",
      "4  On Saturday, August 3, El Paso became the scen...       left  \n",
      "                                                 url  \\\n",
      "0  https://www.foxnews.com/entertainment/australi...   \n",
      "1  https://www.alternet.org/2020/06/law-and-order...   \n",
      "2  https://www.nbcnews.com/news/latino/after-step...   \n",
      "3  https://www.alternet.org/2019/07/fox-news-has-...   \n",
      "4  https://www.alternet.org/2019/08/a-new-low-was...   \n",
      "\n",
      "                                             content type_class  \n",
      "0  \"Orange Is the New Black\" star Yael Stone is r...      right  \n",
      "1  Mark Twain's instruction to curious residents ...       left  \n",
      "2  It wasn't the content of White House adviser S...       left  \n",
      "3  Donald Trump thinks white nationalism is going...       left  \n",
      "4  On Saturday, August 3, El Paso became the scen...       left  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bowmanrussell/Documents/Natural Language Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     article \u001b[39m=\u001b[39m Article(url)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     article\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     article\u001b[39m.\u001b[39mparse()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bowmanrussell/Documents/Natural%20Language%20Proccesses/final_project/NLP_Project_Group3/playing_with_scraping.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     df_scraped \u001b[39m=\u001b[39m df_scraped\u001b[39m.\u001b[39m_append({\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m: url, \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: article\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mtype_class\u001b[39m\u001b[39m'\u001b[39m: type_class}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/newspaper/article.py:170\u001b[0m, in \u001b[0;36mArticle.download\u001b[0;34m(self, input_html, title, recursion_counter)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m input_html \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         html \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mget_html_2XX_only(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m    171\u001b[0m     \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    172\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_state \u001b[39m=\u001b[39m ArticleDownloadState\u001b[39m.\u001b[39mFAILED_RESPONSE\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/newspaper/network.py:62\u001b[0m, in \u001b[0;36mget_html_2XX_only\u001b[0;34m(url, config, response)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_html_from_response(response)\n\u001b[0;32m---> 62\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m     63\u001b[0m     url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mget_request_kwargs(timeout, useragent, proxies, headers))\n\u001b[1;32m     65\u001b[0m html \u001b[39m=\u001b[39m _get_html_from_response(response)\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mhttp_success_only:\n\u001b[1;32m     68\u001b[0m     \u001b[39m# fail if HTTP sends a non 2XX response\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    538\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1411\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1410\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1411\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1412\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:324\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    325\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    326\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:285\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 285\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    287\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1249\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1246\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1248\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1106\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Scrape data using URLs\n",
    "# will take hours\n",
    "df1 = pd.read_csv('urls_BABE.csv')\n",
    "df_scraped = pd.DataFrame(columns=['url', 'content', 'type_class'])\n",
    "print(len(df1))\n",
    "x, hit, miss = 0, 0, 0\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if(x == len(df1)-1):\n",
    "        break\n",
    "    # Iterate over items in the row\n",
    "    url = row['news_link']\n",
    "    url = str(url)\n",
    "    type_class = row['type']\n",
    "    if url != np.nan:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            df_scraped = df_scraped._append({'url': url, 'content': article.text, 'type_class': type_class}, ignore_index=True)\n",
    "            hit += 1\n",
    "            #print('Succesfully grabbed article #' + str(x))\n",
    "            \n",
    "            print(df_scraped.head())\n",
    "        except ArticleException:\n",
    "            miss += 1\n",
    "            #print('***FAILED TO DOWNLOAD***')\n",
    "    x +=1\n",
    "print('\\nSuccesfully scraped ' + str(hit) + ' articles. Missed ' + str(miss))\n",
    "#print(df_scraped.head(20))\n",
    "\n",
    "# Output scraped data csv\n",
    "df_scraped['type_class'] = df_scraped.apply(relable_class, axis=1)\n",
    "#df_scraped.to_csv('scraped_data/BABE_scraped.csv')\n",
    "type_counts = df_scraped['type_class'].value_counts() # eval number of each type_class\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
